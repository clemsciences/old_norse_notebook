{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menota annotated Völuspá"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(AM 242 fol – Codex Wormianus v. 0.9.9) [http://clarino.uib.no/menota/document-element](http://clarino.uib.no/menota/document-element)\n",
    "\n",
    "To use this notebook, I let you download these texts:\n",
    "\n",
    "* [Völuspá in Codex Regius](http://clarino.uib.no/menota/texts/GKS-2365-4to-Vsp.xml)\n",
    "* [Völuspá in Hauksbók](http://clarino.uib.no/menota/texts/AM-544-4to-Vsp.xml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import html\n",
    "from collections import defaultdict\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.sax.saxutils import escape, unescape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can open the digitalized manuscripts here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "konungsbok_filename = \"GKS-2365-4to-Vsp.xml\"\n",
    "hausbok_filename = \"AM-544-4to-Vsp.xml\"\n",
    "menota_directory = \"menota\"\n",
    "# #konungsbok = ET.parse(os.path.join(menota_directory, konungsbok_filename))\n",
    "# # hausbok = ET.parse(os.path.join(menota_directory, hausbok_filename))\n",
    "# with codecs.open(os.path.join(menota_directory, konungsbok_filename), \"r\", encoding=\"utf-8\") as f:\n",
    "#     konungsbok = ET.fromstring(html.unescape(f.read()))\n",
    "# #    ET.parse\n",
    "# #with codecs.open(os.path.join(menota_directory, hausbok_filename), \"r\", encoding=\"utf-8\") as f:\n",
    "# #     hausbok = ET.fromstring(html.unescape(f.read()))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... but this does not work because the namespace of tags is not defined.\n",
    "The **etree** library cannot do that, whereas **lxml** can!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the DTD ([Document Type Definition](https://en.wikipedia.org/wiki/Document_type_definition)) defined inside the document, you can use this text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = etree.XMLParser(load_dtd=True, no_network=False)\n",
    "tree = etree.parse(os.path.join(menota_directory, konungsbok_filename), parser=parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            <me:dipl>ec</me:dipl>\n",
      "                        <me:norm>ek</me:norm>\n",
      "</w>\n",
      "                        <w me:msa=\"xAJ rP gF nP cA sI\" lemma=\"allr\">\n",
      "                            <me:facs>allar</me:facs>\n",
      "                            <me:dipl>allar</me:dipl>\n",
      "                        <me:norm>allar</me:norm>\n",
      "</w>\n",
      "                    </l>\n",
      "                    <l>\n"
     ]
    }
   ],
   "source": [
    "root = tree.getroot()\n",
    "decoded_root = etree.tostring(root).decode(\"utf-8\")\n",
    "i = 170\n",
    "print(\"\\n\".join(decoded_root.split(\"\\n\")[i:i+10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            <me:dipl>ec</me:dipl>\n",
      "                        <me:norm>ek</me:norm>\n",
      "</w>\n",
      "                        <w me:msa=\"xAJ rP gF nP cA sI\" lemma=\"allr\">\n",
      "                            <me:facs>allar</me:facs>\n",
      "                            <me:dipl>allar</me:dipl>\n",
      "                        <me:norm>allar</me:norm>\n",
      "</w>\n",
      "                    </l>\n",
      "                    <l>\n",
      "                        <w me:msa=\"xNC gF nP cA sI\" lemma=\"kind\">\n",
      "                            <me:facs>kin&#42874;ir</me:facs>\n",
      "                            <me:dipl>kin&#42874;ir</me:dipl>\n",
      "                        <me:norm>kindir</me:norm>\n",
      "</w>\n",
      "                    </l>\n",
      "                    <l>\n",
      "                        <w me:msa=\"xAJ rC gF nP cA sD\" lemma=\"mikill\">\n",
      "                            <me:facs>meiri</me:facs>\n",
      "                            <me:dipl>meiri</me:dipl>\n",
      "                        <me:norm>meiri</me:norm>\n",
      "</w>\n",
      "                        <w me:msa=\"xCU\" lemma=\"ok\">\n",
      "                            <me:facs><am>&#8266;</am></me:facs>\n",
      "                            <me:dipl><ex>oc</ex></me:dipl>\n",
      "                        <me:norm>ok</me:norm>\n",
      "</w>\n",
      "                        <w me:msa=\"xAJ rC gF nP cA sD\" lemma=\"l&#237;till\">\n",
      "                            <me:facs>mi&#628;i</me:facs>\n",
      "                            <me:dipl>mi&#628;i</me:dipl>\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(decoded_root.split(\"\\n\")[i:i+30]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{http://www.tei-c.org/ns/1.0}TEI'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stringify = etree.XPath(\"string()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "namespaces = {'n': 'http://www.tei-c.org/ns/1.0',\n",
    "              'me': 'http://www.menota.org/ns/1.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "header, text = root.getchildren()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element {http://www.tei-c.org/ns/1.0}div at 0x7fabec240408>\n"
     ]
    }
   ],
   "source": [
    "print(text.find('.//n:div[@type=\"poem\"]', namespaces=namespaces))\n",
    "poem = text.find('.//n:div[@type=\"poem\"]', namespaces=namespaces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of the poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poem = text.getchildren()[0].getchildren()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanzas = [child for child in poem.xpath(\"n:lg\", namespaces=namespaces)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "facsimile_stanzas = [stanza.findall(\".//n:l\", namespaces=namespaces) for stanza in stanzas]\n",
    "facsimile_lines = [[line.findall(\".//me:facs\", namespaces=namespaces) for line in stanza] for stanza in facsimile_stanzas]\n",
    "facsimile_text = [[[stringify(word) for word in line] for line in stanza ] for stanza in facsimile_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diplomatica_stanzas = [stanza.findall(\".//n:l\", namespaces=namespaces) for stanza in stanzas]\n",
    "diplomatica_lines = [[line.findall(\".//me:dipl\", namespaces=namespaces) for line in stanza] for stanza in diplomatica_stanzas]\n",
    "diplomatica_text = [[[stringify(word) for word in line] for line in stanza ] for stanza in diplomatica_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_stanzas = [stanza.findall(\".//n:l\", namespaces=namespaces) for stanza in stanzas]\n",
    "normalized_lines = [[line.findall(\".//me:norm\", namespaces=namespaces) for line in stanza] for stanza in normalized_stanzas]\n",
    "normalized_text = [[[stringify(word) for word in line] for line in stanza ] for stanza in normalized_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmata_stanzas = [stanza.findall(\".//n:l\", namespaces=namespaces) for stanza in stanzas]\n",
    "lemmata_lines = [[line.findall(\".//n:w\", namespaces=namespaces) for line in stanza] for stanza in lemmata_stanzas]\n",
    "lemmata_text = [[[word.get(\"lemma\") for word in line] for line in stanza ] for stanza in lemmata_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_stanzas = [stanza.findall(\".//n:l\", namespaces=namespaces) for stanza in stanzas]\n",
    "pos_lines = [[line.findall(\".//n:w\", namespaces=namespaces) for line in stanza] for stanza in pos_stanzas]\n",
    "pos_text = [[[word.get('{http://www.menota.org/ns/1.0}msa') for word in line] for line in stanza ] for stanza in pos_lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### First stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hlıoðſ', 'bið', 'ec', 'allar'],\n",
       " ['kinꝺir'],\n",
       " ['meiri', '⁊', 'miɴi'],\n",
       " ['maugo', 'heimꝺalar'],\n",
       " ['uilðo', 'at', 'ec', 'ualꝼꜹþ̅'],\n",
       " ['uel', 'ꝼyr', 'telia'],\n",
       " ['ꝼoꝛn', 'ſpioll', 'ꝼíra'],\n",
       " ['þꜹ', 'e͛', 'ꝼremſt', 'u̅', 'man', '.']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facsimile_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hlıoðſ', 'bið', 'ec', 'allar'],\n",
       " ['kinꝺir'],\n",
       " ['meiri', 'oc', 'miɴi'],\n",
       " ['maugo', 'heimꝺalar'],\n",
       " ['uilðo', 'at', 'ec', 'ualꝼꜹþr'],\n",
       " ['uel', 'ꝼyr', 'telia'],\n",
       " ['ꝼoꝛn', 'ſpioll', 'ꝼíra'],\n",
       " ['þꜹ', 'er', 'ꝼremſt', 'um', 'man', '.']]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diplomatica_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hljóðs', 'bið', 'ek', 'allar'],\n",
       " ['kindir'],\n",
       " ['meiri', 'ok', 'minni'],\n",
       " ['mögu', 'Heimdalar'],\n",
       " ['vildu', 'að', 'ek', 'Valföðr'],\n",
       " ['vel', 'fyr', 'telja'],\n",
       " ['forn', 'spjöll', 'fira'],\n",
       " ['þau', 'er', 'fremst', 'um', 'man', '.']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hlióð', 'biðia', 'ek', 'allr'],\n",
       " ['kind'],\n",
       " ['mikill', 'ok', 'lítill'],\n",
       " ['mǫgr', 'Heimdallr'],\n",
       " ['vilia', 'at', 'ek', 'Valfǫðr'],\n",
       " ['vel', 'fyr', 'telia'],\n",
       " ['forn', 'spiall', 'firar'],\n",
       " ['sá', 'er', 'framr', 'um', 'muna']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmata_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['xNC gN nS cG sI',\n",
       "  'xVB fF tPS mIN p1 nS vA iST',\n",
       "  'xPD cN',\n",
       "  'xAJ rP gF nP cA sI'],\n",
       " ['xNC gF nP cA sI'],\n",
       " ['xAJ rC gF nP cA sD', 'xCU', 'xAJ rC gF nP cA sD'],\n",
       " ['xNC gM nP cA sI', 'xNP gM cG sI'],\n",
       " ['xVB fF tPS mIN p2 nS vA iWK', 'xCU', 'xPD cN', 'xNC gM nS cN'],\n",
       " ['xAV rP', 'xAV rP', 'xVB fF tPS mSU p1 nS vA iWK'],\n",
       " ['xAJ rP gN nP cA sI', 'xNC gN nP cA sI', 'xNC gM nP cG sI'],\n",
       " ['xPD gN nP cA',\n",
       "  'xCU',\n",
       "  'xAJ rS gN nP cA sI',\n",
       "  'xAV rP',\n",
       "  'xVB fF tPS mIN p1 nS vA iPP']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the POS tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "These annotations are ununderstandable without the docs that you can find [here](https://menota.org/HB3_ch11.xml#sec11.3). The idea is to parse these annotations the same way I did in https://github.com/cltk/old_norse_texts_heimskringla/blob/master/pos.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WordClass:\n",
    "    identifier = \"x\"\n",
    "    noun = \"N\"\n",
    "    common_noun = \"NC\"\n",
    "    proper_noun = \"NP\"\n",
    "    adjective = \"AJ\"\n",
    "    pronoun = \"P\"\n",
    "    personal_pronoun = \"PE\"\n",
    "    interrogative_pronoun = \"PQ\"\n",
    "    indefinite_pronouns = \"PI\"\n",
    "    possessive = \"DP\"\n",
    "    demonstrative = \"DD\"\n",
    "    quantifier = \"DQ\"\n",
    "    pronoun = \"PD\"\n",
    "    number = \"N\"\n",
    "    cardinal = \"NA\"\n",
    "    ordinal = \"NO\"\n",
    "    numeral_undetermined = \"NU\"\n",
    "    article = \"AT\"\n",
    "    verb = \"VB\"\n",
    "    adverb = \"AV\"\n",
    "    preposition = \"VP\"\n",
    "    adposition = \"AP\"\n",
    "    conjunction = \"CC\"\n",
    "    subjunction = \"CS\"\n",
    "    conjunction_subjunction = \"CU\"\n",
    "    interjection = \"IT\"\n",
    "    infinitive_marker = \"IM\"\n",
    "    relative_particle = \"RP\"\n",
    "    expletive_particle = \"EX\"\n",
    "    unassigned = \"UA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gender:\n",
    "    identifier = \"g\"\n",
    "    masculine = \"M\"\n",
    "    feminine = \"F\"\n",
    "    neuter = \"N\"\n",
    "    unspecified = \"U\"\n",
    "    \n",
    "    verbose = defaultdict(str)\n",
    "    verbose[masculine] = \"masculine\"\n",
    "    verbose[feminine] = \"feminine\"\n",
    "    verbose[neuter] = \"neuter\"\n",
    "    verbose[unspecified] = \"unspecified\"\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(tag, value):\n",
    "        return value + \" \" + Gender.verbose[tag]\n",
    "\n",
    "    @staticmethod\n",
    "    def can_apply(tag):\n",
    "        return tag in Gender.verbose\n",
    "    \n",
    "    @staticmethod\n",
    "    def binarize(tag, value):\n",
    "        value.masculine = tag == Gender.masculine\n",
    "        value.feminine = tag == Gender.feminine\n",
    "        value.neuter = tag == Gender.neuter\n",
    "        return value\n",
    "    \n",
    "class Number:\n",
    "    identifier = \"n\"\n",
    "    singular = \"S\"\n",
    "    dual = \"D\"\n",
    "    plural = \"P\"\n",
    "    unspecified = \"U\"\n",
    "    \n",
    "    verbose = defaultdict(str)\n",
    "    verbose[singular] = \"singular\"\n",
    "    verbose[plural] = \"plural\"\n",
    "    verbose[dual] = \"dual\"\n",
    "    verbose[unspecified] = \"unspecified\"\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(tag, value):\n",
    "        return value + \" \" + Number.verbose[tag]\n",
    "\n",
    "    @staticmethod\n",
    "    def can_apply(tag):\n",
    "        return tag in Number.verbose\n",
    "    \n",
    "    @staticmethod\n",
    "    def binarize(tag, value):\n",
    "        value.singular = tag == Number.singular\n",
    "        value.plural = tag == Number.plural\n",
    "        value.dual = tag == Number.dual\n",
    "        return value\n",
    "        \n",
    "    \n",
    "class Case:\n",
    "    identifier = \"c\"\n",
    "    nominative = \"N\"\n",
    "    genitive = \"G\"\n",
    "    dative = \"D\"\n",
    "    accusative = \"A\"\n",
    "    oblique = \"O\"\n",
    "    unspecified = \"U\"\n",
    "    \n",
    "    verbose = defaultdict(str)\n",
    "    verbose[nominative] = \"nominative\"\n",
    "    verbose[accusative] = \"feminine\"\n",
    "    verbose[genitive] = \"genitive\"\n",
    "    verbose[dative] = \"dative\"\n",
    "    verbose[oblique] = \"oblique\"\n",
    "    verbose[unspecified] = \"unspecified\"\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(tag, value):\n",
    "        return value + \" \" + Case.verbose[tag]\n",
    "\n",
    "    @staticmethod\n",
    "    def can_apply(tag):\n",
    "        return tag in Case.verbose\n",
    "    \n",
    "    @staticmethod\n",
    "    def binarize(tag, value):\n",
    "        value.nominative = tag == Case.nominative\n",
    "        value.accusative = tag == Case.accusative\n",
    "        value.dative = tag == Case.dative\n",
    "        value.genitive = tag == Case.genitive\n",
    "        return value\n",
    "    \n",
    "class Species:\n",
    "    identifier = \"s\"\n",
    "    indefinite = \"I\"\n",
    "    definite = \"D\"\n",
    "    unspecified = \"U\"\n",
    "    \n",
    "    verbose = defaultdict(str)\n",
    "    verbose[indefinite] = \"indefinite\"\n",
    "    verbose[definite] = \"definite\"\n",
    "    verbose[unspecified] = \"unspecified\"\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(tag, value):\n",
    "        return value + \" \" + Species.verbose[tag]\n",
    "\n",
    "    @staticmethod\n",
    "    def can_apply(tag):\n",
    "        return tag in Species.verbose\n",
    "    \n",
    "    @staticmethod\n",
    "    def binarize(tag, value):\n",
    "        value.definite = tag == Species.definite\n",
    "        value.indefinite = tag == Species.indefinite\n",
    "        return value\n",
    "    \n",
    "class Grade:\n",
    "    identifier = \"r\"\n",
    "    positive = \"P\"\n",
    "    comparative = \"C\"\n",
    "    superlative = \"S\"\n",
    "    unspecified = \"U\"\n",
    "    \n",
    "    verbose = defaultdict(str)\n",
    "    verbose[positive] = \"positive\"\n",
    "    verbose[comparative] = \"comparative\"\n",
    "    verbose[superlative] = \"superlative\"\n",
    "    verbose[unspecified] = \"unspecified\"\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(tag, value):\n",
    "        return value + \" \" + Grade.verbose[tag]\n",
    "\n",
    "    @staticmethod\n",
    "    def can_apply(tag):\n",
    "        return tag in Grade.verbose\n",
    "    \n",
    "    @staticmethod\n",
    "    def binarize(tag, value):\n",
    "        value.positive = tag == Grade.positive\n",
    "        value.comparative = tag == Grade.comparative\n",
    "        value.superlative = tag == Grade.superlative\n",
    "        return value\n",
    "    \n",
    "class Person:\n",
    "    identifier = \"p\"\n",
    "    first = \"1\"\n",
    "    second = \"2\"\n",
    "    third = \"3\"\n",
    "    unspecified = \"U\"\n",
    "    \n",
    "    verbose = defaultdict(str)\n",
    "    verbose[first] = \"first\"\n",
    "    verbose[second] = \"second\"\n",
    "    verbose[third] = \"third\"\n",
    "    verbose[unspecified] = \"unspecified\"\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(tag, value):\n",
    "        return value + \" \" + Person.verbose[tag]\n",
    "\n",
    "    @staticmethod\n",
    "    def can_apply(tag):\n",
    "        return tag in Person.verbose\n",
    "    \n",
    "    @staticmethod\n",
    "    def binarize(tag, value):\n",
    "        value.first = tag == Person.first\n",
    "        value.second = tag == Person.second\n",
    "        value.third = tag == Person.third\n",
    "        return value\n",
    "\n",
    "class Tense:\n",
    "    identifier = \"t\"\n",
    "    present = \"PS\"\n",
    "    preterite = \"PT\"\n",
    "    unspecified = \"U\"\n",
    "    \n",
    "    verbose = defaultdict(str)\n",
    "    verbose[present] = \"present\"\n",
    "    verbose[preterite] = \"preterite\"\n",
    "    verbose[unspecified] = \"unspecified\"\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(tag, value):\n",
    "        return value + \" \" + Tense.verbose[tag]\n",
    "\n",
    "    @staticmethod\n",
    "    def can_apply(tag):\n",
    "        return tag in Tense.verbose\n",
    "    \n",
    "    @staticmethod\n",
    "    def binarize(tag, value):\n",
    "        value.present = tag == Tense.present\n",
    "        value.preterite = tag == Tense.preterite\n",
    "        return value\n",
    "    \n",
    "class Mood:\n",
    "    identifier = \"m\"\n",
    "    indicative = \"IN\"\n",
    "    subjunctive = \"SU\"\n",
    "    imperative = \"IP\"\n",
    "    unspecified = \"U\"\n",
    "    \n",
    "    verbose = defaultdict(str)\n",
    "    verbose[indicative] = \"indicative\"\n",
    "    verbose[subjunctive] = \"subjunctive\"\n",
    "    verbose[imperative] = \"imperative\"\n",
    "    verbose[unspecified] = \"unspecified\"\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(tag, value):\n",
    "        return value + \" \" + Mood.verbose[tag]\n",
    "\n",
    "    @staticmethod\n",
    "    def can_apply(tag):\n",
    "        return tag in Mood.verbose\n",
    "    \n",
    "    @staticmethod\n",
    "    def binarize(tag, value):\n",
    "        value.indicative = tag == Mood.indicative\n",
    "        value.subjunctive = tag == Mood.subjunctive\n",
    "        value.imperative = tag == Mood.imperative\n",
    "        return value\n",
    "    \n",
    "class Voice:\n",
    "    identifier = \"v\"\n",
    "    active = \"A\"\n",
    "    reflexive = \"R\"\n",
    "    unspecified = \"U\"\n",
    "    \n",
    "    verbose = defaultdict(str)\n",
    "    verbose[active] = \"active\"\n",
    "    verbose[reflexive] = \"reflexive\"\n",
    "    verbose[unspecified] = \"unspecified\"\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(tag, value):\n",
    "        return value + \" \" + Voice.verbose[tag]\n",
    "\n",
    "    @staticmethod\n",
    "    def can_apply(tag):\n",
    "        return tag in Voice.verbose\n",
    "    \n",
    "    @staticmethod\n",
    "    def binarize(tag, value):\n",
    "        value.active = tag == Voice.active\n",
    "        value.reflexive = tag == Voice.reflexive\n",
    "        return value\n",
    "    \n",
    "class Finitness:\n",
    "    identifier = \"f\"\n",
    "    finite = \"F\"\n",
    "    infinite = \"I\"\n",
    "    participle = \"P\"\n",
    "    unspecified = \"U\"\n",
    "    \n",
    "    verbose = defaultdict(str)\n",
    "    verbose[finite] = \"finite\"\n",
    "    verbose[infinite] = \"infinite\"\n",
    "    verbose[participle] = \"participle\"\n",
    "    verbose[unspecified] = \"unspecified\"\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(tag, value):\n",
    "        return value + \" \" + Finitness.verbose[tag]\n",
    "\n",
    "    @staticmethod\n",
    "    def can_apply(tag):\n",
    "        return tag in Finitness.verbose\n",
    "    \n",
    "    @staticmethod\n",
    "    def binarize(tag, value):\n",
    "        value.finite = tag == Finitness.finite\n",
    "        value.infinite = tag == Finitness.infinite\n",
    "        value.participle = tag == Finitness.participle\n",
    "        return value\n",
    "    \n",
    "class InflectionalClass:\n",
    "    identifier = \"i\"\n",
    "    strong = \"ST\"\n",
    "    weak = \"WK\"\n",
    "    reduplicating = \"RD\"\n",
    "    preterito_present = \"PP\"\n",
    "    \n",
    "    verbose = defaultdict(str)\n",
    "    verbose[strong] = \"strong\"\n",
    "    verbose[weak] = \"weak\"\n",
    "    verbose[reduplicating] = \"reduplicating\"\n",
    "    verbose[preterito_present] = \"preterito-present\"\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(tag, value):\n",
    "        return value + \" \" + InflectionalClass.verbose[tag]\n",
    "\n",
    "    @staticmethod\n",
    "    def can_apply(tag):\n",
    "        return tag in InflectionalClass.verbose\n",
    "    \n",
    "    @staticmethod\n",
    "    def binarize(tag, value):\n",
    "        value.strong = tag == InflectionalClass.strong\n",
    "        value.weak = tag == InflectionalClass.weak\n",
    "        value.reduplicating = tag == InflectionalClass.reduplicating\n",
    "        value.preterito_present = tag == InflectionalClass.preterito_present\n",
    "        return value\n",
    "    \n",
    "class Enclitic:\n",
    "    identifier = \"e\"\n",
    "    pronoun = \"P\"\n",
    "    negative_particle = \"N\"\n",
    "    \n",
    "    verbose = defaultdict(str)\n",
    "    verbose[pronoun] = \"pronoun\"\n",
    "    verbose[negative_particle] = \"negative particle\"\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(tag, value):\n",
    "        return value + \" \" + Enclitic.verbose[tag]\n",
    "\n",
    "    @staticmethod\n",
    "    def can_apply(tag):\n",
    "        return tag in Enclitic.verbose\n",
    "    \n",
    "    @staticmethod\n",
    "    def binarize(tag, value):\n",
    "        value.pronoun = tag == Enclitic.pronoun\n",
    "        value.negative_particle = tag == Enclitic.negative_particle\n",
    "        return value\n",
    "    \n",
    "class Government:\n",
    "    identifier = \"y\"\n",
    "    genitive = \"G\"\n",
    "    dative = \"D\"\n",
    "    accusative = \"A\"\n",
    "    unspecified = \"U\"\n",
    "    indicative = \"UN\"\n",
    "    subjunctive = \"SU\"\n",
    "    \n",
    "    verbose = defaultdict(str)\n",
    "    verbose[genitive] = \"genitive\"\n",
    "    verbose[dative] = \"dative\"\n",
    "    verbose[accusative] = \"accusative\"\n",
    "    verbose[indicative] = \"indicative\"\n",
    "    verbose[subjunctive] = \"subjunctive\"\n",
    "    verbose[unspecified] = \"unspecified gender\"\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(tag, value):\n",
    "        return value + \" \" + Government.verbose[tag]\n",
    "\n",
    "    @staticmethod\n",
    "    def can_apply(tag):\n",
    "        return tag in Government.verbose\n",
    "    \n",
    "    @staticmethod\n",
    "    def binarize(tag, value):\n",
    "        value.genitive = tag == Government.genitive\n",
    "        value.dative = tag == Government.dative\n",
    "        value.accusative = tag == Government.accusative\n",
    "        value.indicative = tag == Government.indicative\n",
    "        value.subjunctive = tag == Government.subjunctive\n",
    "        return value\n",
    "\n",
    "    \n",
    "DELIMITER = \"|\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POSFeatures:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.masculine = False\n",
    "        self.feminine = False\n",
    "        self.neuter = False\n",
    "        self.singular = False\n",
    "        self.plural = False\n",
    "        self.dual = False\n",
    "        self.nominative = False\n",
    "        self.accusative = False\n",
    "        self.dative = False\n",
    "        self.definite = False\n",
    "        self.indefinite = False\n",
    "        self.positive = False\n",
    "        self.comparative = False\n",
    "        self.superlative = False\n",
    "        self.first = False\n",
    "        self.second = False\n",
    "        self.third = False\n",
    "        self.indicative = False\n",
    "        self.subjunctive = False\n",
    "        self.imperative = False\n",
    "        self.present = False\n",
    "        self.preterite = False\n",
    "        self.active = False\n",
    "        self.reflexive = False\n",
    "        self.infinitive = False\n",
    "        self.participle = False\n",
    "        self.strong = False\n",
    "        self.weak = False\n",
    "        self.reduplicating = False\n",
    "        self.preterito_present = False\n",
    "        self.noun = False\n",
    "        self.adjective = False\n",
    "        self.article = False\n",
    "        self.numeral = False\n",
    "        self.verb = False\n",
    "        self.adverb = False\n",
    "        self.conjunction = False\n",
    "        self.foreign = False\n",
    "        self.punctuation = False\n",
    "        self.unanalysed = False\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        for i in range(len(self.vectorize())):\n",
    "            if self.vectorize()[i] != other.vectorize()[i]:\n",
    "                return False\n",
    "        return True\n",
    "        \n",
    "    def vectorize(self):\n",
    "        return [\n",
    "            self.masculine,\n",
    "            self.feminine,\n",
    "            self.neuter,\n",
    "            self.singular,\n",
    "            self.plural,\n",
    "            self.dual,\n",
    "            self.nominative,\n",
    "            self.accusative,\n",
    "            self.dative,\n",
    "            self.definite,\n",
    "            self.indefinite,\n",
    "            self.positive,\n",
    "            self.comparative,\n",
    "            self.superlative,\n",
    "            self.first,\n",
    "            self.second,\n",
    "            self.third,\n",
    "            self.indicative,\n",
    "            self.subjunctive,\n",
    "            self.imperative,\n",
    "            self.present,\n",
    "            self.preterite,\n",
    "            self.active,\n",
    "            self.reflexive,\n",
    "            self.infinitive,\n",
    "            self.participle,\n",
    "            self.strong,\n",
    "            self.weak,\n",
    "            self.reduplicating,\n",
    "            self.preterito_present,\n",
    "            self.noun,\n",
    "            self.adjective,\n",
    "            self.article,\n",
    "            self.numeral,\n",
    "            self.verb,\n",
    "            self.adverb,\n",
    "            self.foreign,\n",
    "            self.punctuation,\n",
    "            self.unanalysed\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class MainPOS:\n",
    "    noun = \"n\"\n",
    "    adjective = \"l\"\n",
    "    pronoun = \"f\"\n",
    "    article = \"g\"\n",
    "    numeral = \"t\"\n",
    "    verb = \"s\"\n",
    "    adverb = \"a\"\n",
    "    conjunction = \"c\"\n",
    "    foreign = \"e\"\n",
    "    unanalysed = \"x\"\n",
    "    punctuation = \"p\"\n",
    "\n",
    "    verbose = defaultdict(str)\n",
    "    verbose[WordClass.common_noun] = \"common noun\"\n",
    "    verbose[WordClass.proper_noun] = \"proper noun\"\n",
    "    verbose[WordClass.adjective] = \"adjective\"\n",
    "    verbose[WordClass.pronoun] = \"pronoun\"\n",
    "    verbose[WordClass.article] = \"article\"\n",
    "    verbose[WordClass.ordinal] = \"ordinal\"\n",
    "    verbose[WordClass.cardinal] = \"cardinal\"\n",
    "    verbose[WordClass.numeral_undetermined] = \"numeral undetermined\"\n",
    "    verbose[WordClass.verb] = \"verb\"\n",
    "    verbose[WordClass.adverb] = \"adverb\"\n",
    "    verbose[WordClass.conjunction] = \"conjunction\"\n",
    "    verbose[WordClass.subjunction] = \"subjunction\"\n",
    "    verbose[WordClass.conjunction_subjunction] = \"conjunction or subjunction\"\n",
    "    verbose[WordClass.unassigned] = \"unanalysed\"\n",
    "    verbose[WordClass.unassigned] = \"unanalysed\"\n",
    "#     verbose[WordClass.punctuation] = \"punctuation\"\n",
    "#     verbose[WordClass.foreign] = \"foreign\"\n",
    "\n",
    "#     icepac = defaultdict(str)\n",
    "#     icepac[WordClass.comm]\n",
    "\n",
    "    # A universal part-of-speech tagset by Petrov S., Das D., McDonald R.\n",
    "\n",
    "    universal = defaultdict(str)\n",
    "    universal[noun] = \"NOUN\"\n",
    "    universal[adjective] = \"ADJ\"\n",
    "    universal[pronoun] = \"PRON\"\n",
    "    universal[article] = \"DET\"\n",
    "    universal[numeral] = \"NUM\"\n",
    "    universal[verb] = \"VERB\"\n",
    "    universal[adverb] = \"ADV\"  # in this category, belong ADV, ADP and PRT\n",
    "    universal[conjunction] = \"CONJ\"\n",
    "    universal[unanalysed] = \"X\"\n",
    "    universal[foreign] = \"X\"\n",
    "    universal[punctuation] = \"PUNC\"\n",
    "\n",
    "    @staticmethod\n",
    "    def apply(tag: list, l_pos: list, value: str):\n",
    "#         print(tag)\n",
    "        i = 0\n",
    "        for pos in l_pos:\n",
    "#             print(pos)\n",
    "            new_value = \"\"\n",
    "            if isinstance(pos, list):\n",
    "                for j in pos:\n",
    "                    if j.can_apply(tag[i][1:]):\n",
    "                        new_value = j.parse(tag[i], value)\n",
    "            elif i < len(tag):\n",
    "#                 print(tag[i])\n",
    "                new_value = pos.parse(tag[i][1:], value)\n",
    "#                 print(repr(value))\n",
    "            if new_value != \"\" and value+\" \" != new_value:\n",
    "                value = new_value\n",
    "                i += 1\n",
    "        return value\n",
    "    \n",
    "    @staticmethod\n",
    "    def binarize(tag: list, l_pos: list, value: POSFeatures):\n",
    "#         print(tag)\n",
    "        i = 0\n",
    "        for pos in l_pos:\n",
    "            print(pos)\n",
    "            if isinstance(pos, list):\n",
    "                for j in pos:\n",
    "                    if j.can_apply(tag[i][1:]):\n",
    "                        new_value = j.binarize(tag[i], value)\n",
    "            elif i < len(tag):\n",
    "#                 print(tag[i])\n",
    "                new_value = pos.binarize(tag[i][1:], value)\n",
    "#                 print(repr(value))\n",
    "            value = new_value\n",
    "            i += 1\n",
    "        return value\n",
    "\n",
    "    @staticmethod\n",
    "    def parse(full_tag):\n",
    "        \"\"\"\n",
    "        >>> MainPOS.parse('xPE p1 nD cN')\n",
    "        \n",
    "        :param tag:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        features = POSFeatures()\n",
    "        tags = full_tag.split(\" \")\n",
    "        \n",
    "        first_tag = tags[0][0]\n",
    "        if WordClass.identifier == first_tag:\n",
    "            word_class = tags[0][1:]\n",
    "#             print(word_class)\n",
    "            value = \"\"\n",
    "            tag = tags[1:]\n",
    "            if word_class == WordClass.noun:\n",
    "                features.noun = True\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                parsers = [Gender, Number, Case, Species]\n",
    "                value = MainPOS.apply(tag, parsers, value)\n",
    "                features = MainPOS.binarize(tag, parsers, features)\n",
    "                \n",
    "            elif word_class == WordClass.proper_noun:\n",
    "                features.proper_noun = True\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                parsers = [Gender, Number, Case, Species]\n",
    "                value = MainPOS.apply(tag, parsers, value)\n",
    "                features = MainPOS.binarize(tag, parsers, features)\n",
    "                \n",
    "            elif word_class == WordClass.common_noun:\n",
    "                features.common_noun = True\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                parsers = [Gender, Number, Case, Species]\n",
    "                value = MainPOS.apply(tag, parsers, value)\n",
    "                features = MainPOS.binarize(tag, parsers, features)\n",
    "\n",
    "            elif word_class == WordClass.adjective:\n",
    "                features.adjective = True\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                parsers = [Grade, Gender, Number, Case, Species, Grade]\n",
    "                value = MainPOS.apply(tag, parsers, value)\n",
    "                features = MainPOS.binarize(tag, parsers, features)\n",
    "\n",
    "            elif word_class == WordClass.personal_pronoun:\n",
    "                features.personal_pronoun = True\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                parsers = [Person, Gender, Number, Case]\n",
    "                value = MainPOS.apply(tag, parsers, value)\n",
    "                features = MainPOS.binarize(tag, parsers, features)\n",
    "                \n",
    "            elif word_class == WordClass.interrogative_pronoun:\n",
    "                features.interrogative_pronoun = True\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                parsers = [Gender, Number, Case]\n",
    "                value = MainPOS.apply(tag, parsers, value)\n",
    "                features = MainPOS.binarize(tag, parsers, features)\n",
    "                \n",
    "            elif word_class == WordClass.indefinite_pronouns:\n",
    "                features.indefinite_pronouns = True\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                parsers = [Gender, Number, Case]\n",
    "                value = MainPOS.apply(tag, parsers, value)\n",
    "                features = MainPOS.binarize(tag, parsers, features)\n",
    "                \n",
    "            elif word_class == WordClass.possessive:\n",
    "                features.possessive = True\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                parsers = [Gender, Number, Case]\n",
    "                value = MainPOS.apply(tag, parsers, value)\n",
    "                features = MainPOS.binarize(tag, parsers, features)\n",
    "                \n",
    "            elif word_class == WordClass.demonstrative:\n",
    "                features.demonstrative = True\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                parsers = [Gender, Number, Case]\n",
    "                value = MainPOS.apply(tag, parsers, value)\n",
    "                features = MainPOS.binarize(tag, parsers, features)\n",
    "                \n",
    "            elif word_class == WordClass.quantifier:\n",
    "                features.quantifier = True\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                parsers = [Gender, Number, Case]\n",
    "                value = MainPOS.apply(tag, parsers, value)\n",
    "                features = MainPOS.binarize(tag, parsers, features)\n",
    "                \n",
    "            elif word_class == WordClass.article:\n",
    "                features.article = True\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                parsers = [Gender, Number, Case]\n",
    "                value = MainPOS.apply(tag, parsers, value)\n",
    "                features = MainPOS.binarize(tag, parsers, features)\n",
    "            \n",
    "            elif word_class == WordClass.pronoun:\n",
    "                features.pronoun = True\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                parsers = [Person, Gender, Number, Case]\n",
    "                value = MainPOS.apply(tag, parsers, value)\n",
    "                features = MainPOS.binarize(tag, parsers, features)\n",
    "\n",
    "            elif word_class == WordClass.ordinal:\n",
    "                features.ordinal = True\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                parsers = [Gender, Number, Case, Species]\n",
    "                value = MainPOS.apply(tag, parsers, value)\n",
    "                features = MainPOS.binarize(tag, parsers, features)\n",
    "                \n",
    "            elif word_class == WordClass.cardinal:\n",
    "                features.cardinal = True\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                parsers = [Gender, Number, Case, Species]\n",
    "                value = MainPOS.apply(tag, parsers, value)\n",
    "                features = MainPOS.binarize(tag, parsers, features)\n",
    "                \n",
    "            elif word_class == WordClass.numeral_undetermined:\n",
    "                features.numeral = True\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                parsers = [Gender, Number, Case, Species]\n",
    "                value = MainPOS.apply(tag, parsers, value)\n",
    "                features = MainPOS.binarize(tag, parsers, features)\n",
    "                \n",
    "            elif word_class == WordClass.article:\n",
    "                features.article = True\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                parsers = [Gender, Number, Case, Species]\n",
    "                value = MainPOS.apply(tag, parsers, value)\n",
    "                features = MainPOS.binarize(tag, parsers, features)\n",
    "\n",
    "            elif word_class == WordClass.verb:\n",
    "                features.verb = True\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                verb_class = tags[1][1]\n",
    "                if verb_class == \"F\":\n",
    "                    parsers = [Finitness, Tense, Mood, Person, Number, Voice, InflectionalClass]\n",
    "                    value = MainPOS.apply(tag, parsers, value)\n",
    "                    features = MainPOS.binarize(tag, parsers, features)\n",
    "                elif verb_class == \"P\":\n",
    "                    parsers = [Finitness, Tense, Voice, Gender, Number, Case, Species, InflectionalClass]\n",
    "                    value = MainPOS.apply(tag, parsers, value)\n",
    "                    features = MainPOS.binarize(tag, parsers, features)\n",
    "                elif verb_class == \"I\":\n",
    "                    parsers = [Finitness, Tense, Voice, InflectionalClass]\n",
    "                    value = MainPOS.apply(tag, parsers, value)\n",
    "                    features = MainPOS.binarize(tag, parsers, features)\n",
    "                \n",
    "            elif word_class == WordClass.adverb:\n",
    "                features.adverb = True\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                parsers = [Grade]\n",
    "                value = MainPOS.apply(tag, parsers, value)\n",
    "                features = MainPOS.binarize(tag, parsers, features)\n",
    "                \n",
    "            elif word_class == WordClass.preposition:\n",
    "                features.preposition = True\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                parsers = [Government]\n",
    "                value = MainPOS.apply(tag, parsers, value)\n",
    "                features = MainPOS.binarize(tag, parsers, features)\n",
    "                \n",
    "            elif word_class == WordClass.adposition:\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                \n",
    "                \n",
    "            elif word_class == WordClass.conjunction:\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                \n",
    "            elif word_class == WordClass.conjunction_subjunction:\n",
    "                value = MainPOS.verbose[word_class]\n",
    "            \n",
    "            elif word_class == WordClass.subjunction:\n",
    "                value = MainPOS.verbose[word_class]\n",
    "                \n",
    "            return value, features\n",
    "\n",
    "\n",
    "def parse(tag):\n",
    "#     print(tag)\n",
    "    if len(tag) > 0:\n",
    "        value, features = MainPOS.parse(tag)\n",
    "    else:\n",
    "        value = \"\"\n",
    "    return value, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Finitness'>\n",
      "<class '__main__.Tense'>\n",
      "<class '__main__.Voice'>\n",
      "<class '__main__.Gender'>\n",
      "<class '__main__.Number'>\n",
      "<class '__main__.Case'>\n",
      "<class '__main__.Species'>\n",
      "<class '__main__.InflectionalClass'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = parse(\"xVB fP tPT vA gM nS cN sI\")\n",
    "b.vectorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Gender'>\n",
      "<class '__main__.Number'>\n",
      "<class '__main__.Case'>\n",
      "<class '__main__.Species'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('common noun masculine plural dative indefinite',\n",
       " <__main__.POSFeatures at 0x7fabe4278d30>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse(\"xNC gM nP cD sI\") # hestum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Gender'>\n",
      "<class '__main__.Number'>\n",
      "<class '__main__.Case'>\n",
      "<class '__main__.Species'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be str, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-4be178dd7e11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstanza\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" [\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlemmata_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"]\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" -> \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" : \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: must be str, not tuple"
     ]
    }
   ],
   "source": [
    "for i, stanza in enumerate([pos_text[0]]):\n",
    "    for j, line in enumerate(stanza):\n",
    "        for k, pos in enumerate(line):\n",
    "            print(normalized_text[0][j][k]+\" [\"+lemmata_text[0][j][k]+\"]\"+\" -> \"+parse(pos)+\" : \"+pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will become a repository of CLTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Clément Besnier, (visit my [website](https://www.clementbesnier.fr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
